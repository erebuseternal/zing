jess is a set of classes used to build scrapers which return key value pairs
and are configured via css.

All scrapers have two layers, the layer which extracts data from individual
pages, and the layer which controls moving through many pages. jess is concerned
with the former. jess uses the structuring of html around the css used to style
it to make it incredibly simply to configure a class which handles the
process of data extraction.

Big Picture

At a high level, the process jess uses to scrape a page is the following:
jess consumes a configuration file, which tells jess how to construct keys and values
from the html page. The configuration file is composed of rules attached to CSS selectors.
For each selector,
jess grabs all of the tags satisfying to that selector and applies the corresponding rules
to each tag to create a single key and, optionally, a value. These keys and values
are stored in a dictionary composed of those keys and, for each key, the values assigned
to that key.

To use jess the user creates the aforementioned configuration file and
the functions that will be used to extract data from individual tags. jess
will take care of handling which functions are used where given the rules in the configuration.
Then, once the user gives both of these parts to jess' Action class, as well as the page to be
scraped, it only takes a single method call for jess to have the page scraped and in key value form.


THE CONFIGURATION

The configuration file is the place where you
tell jess how it is you would like to create keys and values from your page(s).
Now, since the advent of CSS more and more web pages are structured, in meaningful ways,
around the hooks CSS uses to style them. The reason for this is clear, documents present
structure in their content in a visual manner and therefore the hooks that CSS uses
correlate strongly to the structure of the document. Therefore they are a great place
upon which to hinge the scraping of a web page. As such the configuration file is composed
of a set of CSS selector and declaration blocks of the form:

selector {
  rule1;
  rule2;
}

The selector is simply a CSS selector which will identify tags on an html page. To learn
more about them go here.
The rules in each block have the following form:
type: how;
The type is either key or val, and the how is a what identifies
the way in which we wish to generate the corresponding
key or value. For each CSS block we must have exactly one rule with the type key
and can optionally have at most one rule with a val type.
What these blocks represent is how to create the key and (optionally) value for
any html tag that satisfies the selector at the beginning of the block. For any tag
satisfying that selector these are the functions that will create the key and
(optionally) value for that tag.

Concerning the 'how' portion of each of the rules, it breaks into two types:
a function reference, or a tag reference.

A function reference is simply a string (no spaces and not starting with the string 'get')
that identifies a function in you yourself have written. We will return to this later. Suffice it
to say that the function we are referencing will be used on each of the tags
the selector of our block identifies to create the corresponding key or value.

The other option is a tag reference. These can only be used for rules of the key type. It has the following
form:

get(selector[direction])

selector here is a css selector (for which there must be a block already in
your code) and [direction] is one of ^, <, >. What this 'how' indicates is that jess
should start at the current
tag found by this block's selector, look
for the first tag satisfying the selector in the direction specified by [direction],
get its key, and assign that key to the current tag. The directions specified by ^, <,
and > are up, left, and right respectively. Up means look at the current tag's parent and
siblings, then at its grandparent and its siblings, and so forth and so on. Left means look
for the current tag's siblings moving up the html page, and right means look for the current
tag's siblings moving down the html page. All
of this is extremely useful if you want to do something like make the content of
a paragraph a value and set its key to be the text of the previous header tag.
As a final note on the use of this feature, jess will go through your css blocks in order.
Therefore, if you ask to use a key for a tag which only satisfies a selector which
is further down on your list of css blocks than your current selector's block, jess
will throw an error. This is because the key for that tag hasn't actually been created
yet and so there is nothing to grab.

The Page and Extraction Functions

Before we can talk about the extraction functions, there is another thing
that needs to be pointed out.
jess does not work with html directly, rather it works with a BeautifulSoup soup object
generated from the html you want to scrape. (To read about how to create a
soup object go here.) Therefore when you eventually input your page, it
will be input as soup.

Extraction functions then work on BeautifulSoup tags. As has been already mentioned,
these functions are how
you actually extract information from tags on your page(s). They
must take, as their only input, a beautiful soup tag. Within the function you can perform
whatever operations you want and should have it return some value (go here to
learn how to interact with BeautifulSoup tags). (Note that if the function
is going to return a value that will be used as a key that value
must be a type which can be a dictionary key). For each of these functions
you have to choose a name by which to reference the function in the configuration
file. Then, for each function you put it in a dictionary under the name
that you chose to reference the function by. This dictionary is what will be input
to jess. When jess is then run on your page, whenever it finds a tag whose
key or value is created by one of those referenced functions, it will grab the function
from the dictionary and call it on the tag, setting the output as the corresponding
key or value.

The Action class

The class that you will use to scrape pages is the Action class.
This class handles parsing the rules in the configuration file, grabbing html
tags from your page based off of the selectors in that configuration file, applying the
corresponding rules to generate keys and values (and keeping track of keys in case
another tag wants a previous tag's key), and placing these keys
and values in a dictionary. All it needs is the plan of action from you (i.e.
the configuration file) and the functions it will use to extract data (your
extraction functions).

As such, Action's constructor takes as input the
address of the configuration file on your machine, and the dictionary of functions aforementioned.

Now, once you have an Action class initialized, scraping everything is quite simple.
To pass in the soup you are going to scrape, call the SetVillain method with your
soup as input. Then, call Act with no input to scrape the document. Finally call DumpVillain
(also with no input) to retrieve a copy of the dictionary that your Action produced.
With that you are done.
(Remember, for each key in the dictionary that results, the value corresponding
to that key is actually the list of values assigned to that key during the scraping.)

Now, at this point, you are probably thinking, "what kind of method names are those?!".
Well here's the reason for them:

Scrapers are also known as Spiders, and I love Marvel Comics, so of course I decided
to name the first versions of this code SpiderWoman. But I thought this name was
a bit long, so I renamed it jess after Jessica Drew (who was SpiderWoman for a bit).
Then, I imagined each web scrape as a battle between SpiderWoman and a Villain (the
page to be scraped). The configuration was the plan of attack, and the
functions were her weapons. (you can set both manually on an Action instance using the LoadPlan and
SetWeapons methods). Then she would set her sights on the villain (thus SetVillain),
act out her plan of attack (thus Act), and finally, once she was done, dump the
villain (thus DumpVillain). So that's why the names are so strange.

RECAP

So, to scrape a page:

Create a configuration file to tell jess how it should generate keys and values
from the page made of css blocks of the form:
selector {
  type: how;
  type: how;
}
where you must have exactly one key rule, and at most one val rule.

Then, create the functions you have referenced in your configuration file, and
place them in a single dictionary where the key for each function is the name
you referenced it by in the configuration file.

Next, create an jess.Action instance with the first input being the address of
the configuration file you wrote, and the second being the dictionary
of functions.

Then, input the page (as soup) by calling SetVillain(soup) with your soup as input on
your Action instance, Scrape
with Act(), and, finally, retrieve your result with DumpVillain().
